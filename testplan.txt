This project had many parts to each, so there was a lot of testing that had to be done to ensure everything was working correctly.

1.)  Starting off, we had to ensure that we received the correct number of arguments, and the correct arguments themselves. This includes making sure only 'b' 'd' 'c' or 'R' is given. Depending on which one or combo, we had to ensure the arguments were valid. This also includes making sure that either the given HuffmanCodeBook, directory or file is valid before proceeding.

2.) After making sure the arguments and the specifics are valid, we can continue to test the program further. Starting with the creating of the codebook, we had to make sure that there was only one code book no matter how many times build was called. It also needed to properly rebuild itself if called on different files/directories. In this case, we delete the codebook (if it exists) first. Then build up the codebook completely from scratch. This ensures only one codebook will be built at any given time in the current directory where the exec is. It is also crucial out codebook tokenizes strings correctly. The same tokenizer that creates tokens for the codebook is also used in compression, so its critical it works as expected. We tested out program against all the control codes we could find. If any control code is encountered, we make sure to treat it as such. For instance, if we write \n in a file and hit a newline, the codebook will have two \n's, one for the control code and one for the string. When we decompress, we also make sure that our program knows the difference between the two. After ensureing we have our control codes working as expected and our program tokenizes perfectly, testing with a bunch of odd test files and even the code for this project, we continued on. 

3.) Once we know that the codebook is always going to be valid and updated with the most recent build, we can test the compile. Compiling is a little tricky, as not only does it have to ensure it is writing the correct bit sequences, it has to make sure all the words are in the codebook. If there is ever a case where a token in a file is not in the code book, this means the file cannot be compressed correctly and any work up to that point is deleted. The file will not be touched by compress/decompress unless the codebook is rebuilt again with the included file contents inside it. We tested compiling single files and directories with/without subdirectories to a large extent. We also tested empty files and very large files. Once everything worked as expected, we moved onto decompress.

4.) Decompress is similar to compress. We had to make sure the decompress was only decompressing the valid .hcz files, anything else is left out. Checking for this was fairly simple, but we also had to make sure that we overwrite the original file with the new one. To accomplish this, we first write to a temp file, delete the original, and then change the temp file name to the original file. This ensures that the original file is comprised of the decompression.

5.) For each of these cases, we made to to test for repeated calling of the same command. In the case of compress, the way we handle it is it will only compress a file to a .hcz file. If a .hcz file exists for a file already, it is deleted and recompiled. For decompile, we are only decompiling .hcz files. Building the codebook gets rebuilt every time -b is called, so there are no worries of errors occuring in this case as well.

We tested our program through numerous trials. All in all, I think it could have been made more efficient, but we are happy with the outcome of the project. We can compress and decompress 1,251 lines of code in 10 seconds with 0 loss of data, which we are proud of.
